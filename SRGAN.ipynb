{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dW3dPaCbBls_"
   },
   "source": [
    "original code from: https://github.com/eriklindernoren/Keras-GAN/tree/master/srgan\n",
    "\n",
    "Author @kurapan\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvyxFzRy3Au2"
   },
   "source": [
    "**Intall Keras Contrib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6c5Ahn1joJs"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3ynpeu7elBbQ",
    "outputId": "714603ca-023b-45da-aa1c-416d5d61e6d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive    # go to the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYBQ9dYl31We"
   },
   "source": [
    "**Data Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_7CvKuZ3x22"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import scipy.misc\n",
    "import cv2\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "\n",
    "    def load_data(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"test\"\n",
    "        \n",
    "        path = glob('/content/drive/My Drive/RelativisticGAN-Tensorflow/dataset/covid/*')   # Working directory of SRGAN for Covid 19\n",
    "\n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "\n",
    "        imgs_hr = []\n",
    "        imgs_lr = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "\n",
    "            h, w = self.img_res\n",
    "            low_h, low_w = int(h / 4), int(w / 4)\n",
    "\n",
    "            img_hr = cv2.resize(img, self.img_res)\n",
    "            img_lr = cv2.resize(img, (low_h, low_w))\n",
    "\n",
    "            # If training => do random flip\n",
    "            if not is_testing and np.random.random() < 0.5:\n",
    "                img_hr = np.fliplr(img_hr)\n",
    "                img_lr = np.fliplr(img_lr)\n",
    "\n",
    "            imgs_hr.append(img_hr)\n",
    "            imgs_lr.append(img_lr)\n",
    "\n",
    "        imgs_hr = np.array(imgs_hr) / 127.5 - 1.\n",
    "        imgs_lr = np.array(imgs_lr) / 127.5 - 1.\n",
    "\n",
    "        return imgs_hr, imgs_lr\n",
    "\n",
    "\n",
    "    def imread(self, path):\n",
    "        return imageio.imread(path).astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rL9sQBTI35Vv"
   },
   "source": [
    "**SRGAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUs1wfkwjVXw"
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "import scipy.misc\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# from data_loader import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "import keras.backend as K\n",
    "sess= tf.compat.v1.Session()\n",
    "graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "class SRGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.channels = 3\n",
    "        self.lr_height = 64                 # Low resolution height\n",
    "        self.lr_width = 64                  # Low resolution width\n",
    "        self.lr_shape = (self.lr_height, self.lr_width, self.channels)\n",
    "        self.hr_height = self.lr_height*4   # High resolution height\n",
    "        self.hr_width = self.lr_width*4     # High resolution width\n",
    "        self.hr_shape = (self.hr_height, self.hr_width, self.channels)\n",
    "\n",
    "        # Number of residual blocks in the generator\n",
    "        self.n_residual_blocks = 16\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # We use a pre-trained VGG19 model to extract image features from the high resolution\n",
    "        # and the generated high resolution images and minimize the mse between them\n",
    "        self.vgg = self.build_vgg()\n",
    "        self.vgg.trainable = False\n",
    "        self.vgg.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'covid19'\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.hr_height, self.hr_width))\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.hr_height / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # High res. and low res. images\n",
    "        img_hr = Input(shape=self.hr_shape)\n",
    "        img_lr = Input(shape=self.lr_shape)\n",
    "\n",
    "        # Generate high res. version from low res.\n",
    "        fake_hr = self.generator(img_lr)\n",
    "\n",
    "        # Extract image features of the generated img\n",
    "        fake_features = self.vgg(fake_hr)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminator determines validity of generated high res. images\n",
    "        validity = self.discriminator(fake_hr)\n",
    "\n",
    "        self.combined = Model([img_lr, img_hr], [validity, fake_features])\n",
    "        self.combined.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1],\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_vgg(self):\n",
    "        \"\"\"\n",
    "        Builds a pre-trained VGG19 model that outputs image features extracted at the\n",
    "        third block of the model\n",
    "        \"\"\"\n",
    "        set_session(sess)\n",
    "\n",
    "        vgg = VGG19(weights=\"imagenet\")\n",
    "        # Set outputs to outputs of last conv. layer in block 3\n",
    "        # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
    "        vgg.outputs = [vgg.layers[9].output]\n",
    "\n",
    "        img = Input(shape=self.hr_shape)\n",
    "\n",
    "        # Extract image features\n",
    "        img_features = vgg(img)\n",
    "\n",
    "        return Model(img, img_features)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        def residual_block(layer_input, filters):\n",
    "            \"\"\"Residual block described in paper\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
    "            d = Activation('relu')(d)\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Add()([d, layer_input])\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(256, kernel_size=3, strides=1, padding='same')(u)\n",
    "            u = Activation('relu')(u)\n",
    "            return u\n",
    "\n",
    "        # Low resolution image input\n",
    "        img_lr = Input(shape=self.lr_shape)\n",
    "\n",
    "        # Pre-residual block\n",
    "        c1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(img_lr)\n",
    "        c1 = Activation('relu')(c1)\n",
    "\n",
    "        # Propogate through residual blocks\n",
    "        r = residual_block(c1, self.gf)\n",
    "        for _ in range(self.n_residual_blocks - 1):\n",
    "            r = residual_block(r, self.gf)\n",
    "\n",
    "        # Post-residual block\n",
    "        c2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)\n",
    "        c2 = BatchNormalization(momentum=0.8)(c2)\n",
    "        c2 = Add()([c2, c1])\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(c2)\n",
    "        u2 = deconv2d(u1)\n",
    "\n",
    "        # Generate high resolution output\n",
    "        gen_hr = Conv2D(self.channels, kernel_size=9, strides=1, padding='same', activation='tanh')(u2)\n",
    "\n",
    "        return Model(img_lr, gen_hr)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_block(layer_input, filters, strides=1, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        # Input img\n",
    "        d0 = Input(shape=self.hr_shape)\n",
    "\n",
    "        d1 = d_block(d0, self.df, bn=False)\n",
    "        d2 = d_block(d1, self.df, strides=2)\n",
    "        d3 = d_block(d2, self.df*2)\n",
    "        d4 = d_block(d3, self.df*2, strides=2)\n",
    "        d5 = d_block(d4, self.df*4)\n",
    "        d6 = d_block(d5, self.df*4, strides=2)\n",
    "        d7 = d_block(d6, self.df*8)\n",
    "        d8 = d_block(d7, self.df*8, strides=2)\n",
    "\n",
    "        d9 = Dense(self.df*16)(d8)\n",
    "        d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "        validity = Dense(1, activation='sigmoid')(d10)\n",
    "\n",
    "        return Model(d0, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ----------------------\n",
    "            #  Train Discriminator\n",
    "            # ----------------------\n",
    "\n",
    "            # Sample images and their conditioning counterparts\n",
    "            imgs_hr, imgs_lr = self.data_loader.load_data(batch_size)\n",
    "\n",
    "            # From low res. image generate high res. version\n",
    "            fake_hr = self.generator.predict(imgs_lr)\n",
    "\n",
    "            valid = np.ones((batch_size,) + self.disc_patch)\n",
    "            fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "            # Train the discriminators (original images = real / generated = Fake)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs_hr, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(fake_hr, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ------------------\n",
    "            #  Train Generator\n",
    "            # ------------------\n",
    "\n",
    "            # Sample images and their conditioning counterparts\n",
    "            imgs_hr, imgs_lr = self.data_loader.load_data(batch_size)\n",
    "\n",
    "            # The generators want the discriminators to label the generated images as real\n",
    "            valid = np.ones((batch_size,) + self.disc_patch)\n",
    "\n",
    "            # Extract ground truth image features using pre-trained VGG19 model\n",
    "            image_features = self.vgg.predict(imgs_hr)\n",
    "\n",
    "            # Train the generators\n",
    "            g_loss = self.combined.train_on_batch([imgs_lr, imgs_hr], [valid, image_features])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "            # Plot the progress\n",
    "            if epoch % sample_interval == 0:\n",
    "                print (\"%d time: %s\" % (epoch, elapsed_time))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "            if epoch % (sample_interval*100)== 0:\n",
    "                self.generator.save_weights(\"/content/drive/My Drive/model/generator_{}.hdf5\".format(epoch), True)\n",
    "                self.discriminator.save_weights(\"/content/drive/My Drive/model/discriminator_{}.hdf5\".format(epoch), True)\n",
    "              \n",
    "\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        # os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n",
    "        r, c = 2, 2\n",
    "\n",
    "        imgs_hr, imgs_lr = self.data_loader.load_data(batch_size=2, is_testing=True)\n",
    "        fake_hr = self.generator.predict(imgs_lr)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        imgs_lr = 0.5 * imgs_lr + 0.5\n",
    "        fake_hr = 0.5 * fake_hr + 0.5\n",
    "        imgs_hr = 0.5 * imgs_hr + 0.5\n",
    "\n",
    "        # Save generated images and the high resolution originals\n",
    "        titles = ['Generated', 'Original']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for row in range(r):\n",
    "            for col, image in enumerate([fake_hr, imgs_hr]):\n",
    "                axs[row, col].imshow(image[row])\n",
    "                axs[row, col].set_title(titles[col])\n",
    "                axs[row, col].axis('off')\n",
    "            cnt += 1\n",
    "        print(fake_hr.shape)\n",
    "        fig.savefig(\"/content/drive/My Drive/images/covid19/%d.png\" % (epoch))\n",
    "        plt.close()\n",
    "\n",
    "      \n",
    "\n",
    "        # Save low resolution images for comparison\n",
    "        for i in range(r):\n",
    "            fig = plt.figure()\n",
    "            plt.imshow(imgs_lr[i])\n",
    "            fig.savefig('/content/drive/My Drive/images/covid19/%d_lowres%d.png' % (epoch, i))\n",
    "            plt.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = SRGAN()\n",
    "    gan.train(epochs=100000, batch_size=1, sample_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "umjGqv_d5CCR"
   },
   "source": [
    "**Load the weights for 80000 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4yLk9zqgF8i"
   },
   "outputs": [],
   "source": [
    "c=SRGAN()\n",
    "c.generator.load_weights(\"/content/drive/My Drive/model/generator_80001.hdf5\")\n",
    "c.discriminator.load_weights(\"/content/drive/My Drive/model/discriminator_80001.hdf5\")\n",
    "\n",
    "# aaa=c.generator.predict(img_lr)\n",
    "# bbb=c.generator.predict(img_lr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XF1lY8jC5Myj"
   },
   "source": [
    "**Unzip the Pics from DCGAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZKbk1T4xXC8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from os.path import join, getsize\n",
    "def unzip_file(zip_src, dst_dir):\n",
    "    r = zipfile.is_zipfile(zip_src)\n",
    "    if r:     \n",
    "        fz = zipfile.ZipFile(zip_src, 'r')\n",
    "        for file in fz.namelist():\n",
    "            fz.extract(file, dst_dir)       \n",
    "    else:\n",
    "        print('This is not zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSd98TLKxZfY"
   },
   "outputs": [],
   "source": [
    "unzip_file(\"/content/drive/My Drive/generated_images_COVID19_1000.zip\",\"/content/drive/My Drive/Covid19_1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCYlOy4Q6g9E"
   },
   "source": [
    "**Pre-processing of the DCGAN pics to size 64*64**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnpU-wyJT-hH"
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "path = glob('/content/drive/My Drive/Covid19_1000/generated_images_COVID19_1000/*')\n",
    "\n",
    "imgs=[]\n",
    "img1s=[]\n",
    "for i in range(len(path)):\n",
    " \n",
    "  img=cv2.imread(path[i])\n",
    "  img1=cv2.resize(img, (64,64))\n",
    "  img1= np.array(img1) / 127.5 - 1.\n",
    "  img1=np.expand_dims(img1,axis=0)\n",
    "  img1s.append(img1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18rjgacm6wYp"
   },
   "source": [
    "**SRGAN to generate super resolution pics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRyzfW-31tgc"
   },
   "outputs": [],
   "source": [
    "for i in range(len(img1s)):\n",
    "  aaa=c.generator.predict(img1s[i])\n",
    "  aaa = 0.5 * aaa + 0.5\n",
    "  plt.imshow(aaa[0,:,:,:])\n",
    "  plt.axis('off')\n",
    "  plt.savefig(\"/content/drive/My Drive/final_presentation/covid19_SRGAN2_{}.jpg\".format(i),bbox_inches='tight',pad_inches=0.0)\n",
    "  plt.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SRGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
